---
title: "RSSp vs ldsc (High PVE)"
author: "Nicholas Knoblauch"
date: 2017-11-08
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->



```{r load_data,echo=F,message=F}
library(tidyverse)
library(RSSp)

ldsc_gwas_resf <- "~/Dropbox/PolygenicRSS/output/RSSp_snakemake/sim_scz2_gwas_ldsc_res_HighPVE.txt.gz"
rss_gwas_resf <-  "~/Dropbox/PolygenicRSS/output/RSSp_snakemake/sim_scz2_gwas_RSSp_res_ALL_HighPVE.txt.gz"
orss_gwas_resf <- "~/Dropbox/PolygenicRSS/output/RSSp_snakemake/sim_scz2_gwas_RSSp_oracle_res_ALL_HighPVE.txt.gz"


est_df <- read_delim(rss_gwas_resf,delim="\t") %>% 
  filter(!log_params,shrinkage==min(shrinkage),pv==max(pv)) %>% 
  select(-log_params) %>% 
  mutate(fgeneid=as.character(fgeneid),rel_bias=round(tbias/tpve,2),
         rel_pve_error=(abs(pve-tpve)/(pve+tpve)),method=paste0("RSSp_",method))


tparam_df<- distinct(est_df,fgeneid,tsigu,tbias,p_n,tpve)

comp_est_df <-  select(est_df,fgeneid,sigu,bias,method,p_n,pve) 

ldsc_est_df <- read_delim(ldsc_gwas_resf,delim="\t") %>% mutate(fgeneid=as.character(fgeneid)) %>% inner_join(tparam_df)
comp_ldsc_est_df <- mutate(
  ldsc_est_df,
  sigu=sqrt(Total_Observed_scale_h2/p_n),
  method="LDSC"
  ) %>% select(
    pve=Total_Observed_scale_h2,
    fgeneid,
    bias=Intercept,
    sigu,
    method,
    p_n) %>% mutate(bias=bias-1)
comp_est_df <- rbind(comp_est_df,comp_ldsc_est_df) %>% inner_join(tparam_df)
comp_est_df <- mutate(
  comp_est_df,
  t_rel_bias=round(tbias/tpve,3),
  est_rel_bias=bias/calc_pve(sigu,p_n),
  perc_tsigu=ntile(tsigu,3)
  )


```

# Simulation

##GWAS summary stats




The loci used in the simulation consisted of the  844500 SNPs that formed the intersection of 

Genotype data came from ~ 450 Europeans in 1kg (1 thousand genomes).  $\hat{\textbf{u}}$ was simulated using the method [outlined here](simulation.html).  $PVE$ took on 9 values between from  $0.09999$ to $0.9999$. Confounding was simulated as a proportion of total $PVE$, and took on one of three values: $0$,$0.05$,$0.1$.  Each scenario was replicated 15 times.    

## LD

`LDshrink` was used to estimate $LD$ for the same 450 individuals from 1kg.  Haplotypes, rather than genotypes were used, and a genetic map was also used.  pre-published `ldetect` breakpoints were used so that the LD matrix could be approximated as block-diagional (blocks are not of equal size)

## Loci
Loci for this simulation were chosen by taking the intersection of:
* Loci typed (or imputed) from the 1kg reference panel
* Loci for which there was a genetic map value
* Loci that fell within `ldetect` break points
* Loci included in the LD score regression example GWAS data

This ended up being `844501` SNPs in total.

<!-- ```{r} -->
<!-- select(comp_est_df,True_PVE=tpve,True_Confound=tbias) %>% distinct(True_PVE,True_Confound) %>% mutate(Relative_Confounding=True_Confound/True_PVE) %>% arrange(True_PVE,True_Confound) -->
<!-- ``` -->

## Methods

* `RSSp` one parameter model. (No confounding parameter)
* `RSSp` two paramter model. 
* LD score regression (`LDSC`) 


The first result I want to highlight is just the relative performance of the three methods: `LDSC`, `RSSp` with a confounding parameter (`RSSp_Confound`), and `RSSp` without a confounding parameter (`RSSp_NoConfound`).  "Performance" here means the RMSE of PVE `abs(pve-true_pve)`  In these simulations there is no confounding. __NB:__ Because `RSSp` bounds PVE between 0 and 1, __I have bounded `LDSC` estimates between 0 and 1__ for the purpose of comparing RMSE between methods. 

```{r rmse_pve}
tpvev <- unique(comp_est_df$tpve)
nlabel_both <- partial(label_both,sep=":\n")

mutate(comp_est_df,tgrp=paste0(tpve,method),rel_confounding=round(tbias/tpve,4),pve=ifelse(pve>1,1,pve)) %>% mutate(true_pve=round(tpve,3),pve=ifelse(pve<0,0,pve)) %>% filter(tbias==0) %>%  ggplot(aes(x=tpve,y=abs(pve-true_pve),group=tgrp,fill=method))+
  geom_boxplot()+
  ylab(bquote(RMSE[PVE]))+xlab(bquote(PVE))+ggtitle("RMSE of PVE","No Confounding (LDSC bounded between 0 and 1)")
```



Next we see the simulation results that had a confounding parameter. Here I've split up the results using the variable `rel_confounding`, which is the level of true confounding divided by the true $PVE$. 
```{r}
mutate(comp_est_df,tgrp=paste0(tpve,method),rel_confounding=round(tbias/tpve,4),pve=ifelse(pve>1,1,pve)) %>% mutate(true_pve=round(tpve,3),pve=ifelse(pve<0,0,pve))  %>%  ggplot(aes(x=tpve,y=abs(pve-true_pve),group=tgrp,fill=method))+
  geom_boxplot()+facet_grid(rel_confounding~.,labeller = nlabel_both)+
  ylab(bquote(RMSE[PVE]))+xlab(bquote(PVE))+ggtitle("RMSE of PVE","(LDSC bounded between 0 and 1)")
```


The next several plots show the same data as the box plots, (RMSE of PVE across methods,levels of counfounding, and true PVE), but are rearranged in several different ways, to make particular comparisons easier. (e.g how does the `RSSp_Confound` method perform as confounding increases at a given `PVE`).  If it looks like RMSE is less than 0 or greater than one, that is simply an artifact of the plotting

```{r joy_bias_pve}
library(ggjoy)
mutate(comp_est_df,rel_confounding=round(tbias/tpve,3),true_pve=round(tpve,3)) %>% filter(true_pve<1) %>% mutate(pve=ifelse(pve>1,1,pve)) %>% mutate(true_pve=round(tpve,3),pve=ifelse(pve<0,0,pve)) %>%  ggplot(aes(x=abs(pve-true_pve),y=method,fill=method))+geom_joy()+xlab(bquote(RMSE[PVE]))+facet_grid(true_pve~rel_confounding,labeller=partial(label_both,sep="\n"))+scale_x_log10()
```
```{r joy_pve_bias}

mutate(comp_est_df,rel_confounding=round(tbias/tpve,3),true_pve=round(tpve,3)) %>% filter(true_pve<1) %>%  mutate(pve=ifelse(pve>1,1,pve)) %>% mutate(true_pve=round(tpve,3),pve=ifelse(pve<0,0,pve)) %>%  ggplot(aes(x=abs(pve-true_pve),y=factor(true_pve),fill=method))+geom_joy()+xlab(bquote(RMSE[PVE]))+facet_grid(method~rel_confounding,labeller=partial(label_both,sep=":\n"))+ylab(bquote(PVE))
```



```{r joy_bias_pve_rmse}
mutate(comp_est_df,rel_confounding=round(tbias/tpve,3),true_pve=round(tpve,3)) %>% filter(true_pve<1) %>% mutate(pve=ifelse(pve>1,1,pve)) %>% mutate(true_pve=round(tpve,3),pve=ifelse(pve<0,0,pve)) %>%  ggplot(aes(x=abs(pve-true_pve),y=factor(rel_confounding),fill=method))+geom_joy()+xlab(bquote(RMSE[PVE]))+facet_grid(true_pve~method,labeller=partial(label_both,sep=":\n"))+ylab(bquote(frac(c,PVE)))
```


This plot shows estimates of $PVE$ vs the true value, In this plot I have not truncated $LDSC$ between 0 and 1.  

```{r pve_tpve}
mutate(comp_est_df,rel_confounding=round(tbias/tpve,3))  %>% ggplot(aes(x=tpve,y=pve,color=method))+
  geom_point()+geom_smooth(method="lm")+
  facet_grid(method~rel_confounding,labeller=nlabel_both)+
  geom_abline(slope=1,intercept=0)+xlab(bquote(PVE))+ylab(bquote(hat(PVE)))+ggtitle("Estimated PVE vs True PVE")
```




```{r pve_tpve_bound}
mutate(comp_est_df,rel_confounding=round(tbias/tpve,3)) %>%  mutate(true_pve=round(tpve,3),pve=ifelse(pve<0,0,pve)) %>% mutate(pve=ifelse(pve>1,1,pve)) %>% ggplot(aes(x=tpve,y=pve,color=method))+
  geom_point()+geom_smooth(method="lm")+
  facet_grid(method~rel_confounding,labeller=nlabel_both)+
  geom_abline(slope=1,intercept=0)+xlab(bquote(PVE))+ylab(bquote(hat(PVE)))+ggtitle("Estimated PVE vs True PVE","Bounding LDSC between 0 and 1")
```




```{r pve_tpve_bound_zoom}
mutate(comp_est_df,rel_confounding=round(tbias/tpve,3)) %>% filter(method!="RSSp_NoConfound") %>%  mutate(true_pve=round(tpve,3),pve=ifelse(pve<0,0,pve)) %>% mutate(pve=ifelse(pve>1,1,pve)) %>% ggplot(aes(x=tpve,y=pve,color=method))+
  geom_point()+geom_smooth(method="lm")+
  facet_grid(method~rel_confounding,labeller=nlabel_both)+
  geom_abline(slope=1,intercept=0)+xlab(bquote(PVE))+ylab(bquote(hat(PVE)))+ggtitle("Estimated PVE vs True PVE","Bounding LDSC between 0 and 1")
```




```{r est_confound_method}
filter(comp_est_df,method!="RSSp_NoConfound") %>% mutate(t_rel_confounding=round(tbias/tpve,3),true_pve=round(tpve,2)) %>% ggplot(aes(x=tbias/tpve,y=bias/tpve))+
  geom_point()+geom_smooth(method="lm")+
  facet_wrap(~method,labeller=partial(label_both,sep=":\n"),scales = "free_y")+
  geom_abline(slope=1,intercept=0)+xlab(bquote(frac(c,PVE)))+ylab(bquote(frac(hat(c),PVE)))+ggtitle("Estimated Relative Confounding")
```



```{r}
tpvev <- unique(comp_est_df$tpve)

mutate(comp_est_df,rel_confounding=round(tbias/tpve,4),tgrp=paste0(rel_confounding,method),pve=ifelse(pve>1,1,pve)) %>% filter(method!="RSSp_NoConfound") %>% mutate(true_pve=round(tpve,3),pve=ifelse(pve<0,0,pve))  %>%  ggplot(aes(x=rel_confounding,y=abs(bias-tbias)/tpve,group=tgrp,fill=method))+
  geom_boxplot()+
  ylab(bquote(frac(RMSE(c),PVE)))+xlab(bquote(frac(c,PVE)))+ggtitle("RMSE of Confounding")
```

```{r est_pve_tpve_method}
filter(comp_est_df,method!="RSSp_NoConfound") %>% mutate(t_rel_confounding=round(tbias/tpve,3),true_pve=round(tpve,2)) %>% ggplot(aes(x=tbias,y=bias))+
  geom_point()+geom_smooth(method="lm")+
  facet_wrap(~method,labeller=partial(label_both,sep=":\n"),scales = "free_y")+
  geom_abline(slope=1,intercept=0)+xlab(bquote(c))+ylab(bquote(hat(c)))+ggtitle("Estimated Confounding vs True Confounding","Across all PVE")
```


## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```




