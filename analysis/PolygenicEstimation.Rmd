---
title: "Polygenic Estimation With and Without Confounding"
author: "Nicholas Knoblauch"
date: 2017-07-28
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->


<!-- # Background -->

<!-- ##General properties of compound normal -->

<!-- If $$x|\mu \sim N(A\mu,\Sigma)$$ and $$\mu \sim N(\rho,\Lambda)$$ then the marginalized form of $x$ is $$x \sim N(A\rho,A \Lambda A^{T} + \Sigma)$$ -->

<!-- ## RSS polygenic prior on $\beta$ -->

<!-- According to the RSS likelihood: -->

<!-- $$\hat{\beta}|\beta \sim N(SRS^{-1}\beta,SRS)$$ Where $R$ is the population LD matrix, and $S$ is a diagonal matrix with entires $S_{jj}=\frac{1}{\text{se}(\hat{\beta}_j)}$  This means that if $\beta \sim N(0,I\sigma_{\beta}^2)$ , then we can obtain the the marginalized form of $\hat{\beta}$ by substituting $$A=SRS^{-1}$$ $$\rho=0$$ $$\Lambda=I\sigma_{\beta}^2$$  and $$\Sigma=SRS$$ -->


<!-- $$\hat{\beta} \sim N(0,(SRS^{-1})I\sigma_{\beta}^2(SRS^{-1})^{T}+SRS)=N(0,\sigma_{\beta}^2 SRS^{-2}RS+SRS)$$ -->

# RSS with standardized effect size and polygenic prior

If we define $\hat{u_i}=\hat{\beta_i}/s_i$ ,the likelihood becomes

$$\hat{u}|u \sim N(Ru,R)$$

The marginalized form is 

$$\hat{u} \sim N(0,\sigma^2_uR^2+R)$$
Let $V(\sigma_u) = \sigma_u^2R^2+R=\sigma^2_u(R+\frac{1}{\sigma^2_u}I)R$

Using an eigen decomposition of $R$ ($R=QDQ^T$), we arrive at the log-likelihood function:

$$l(\sigma_u)=-\frac{1}{2}\left[\sum_i \log(d_i\sigma_u^2+1) + \hat{u}^TQ\text{diag}(\frac{1}{d_i^2\sigma_u^2+d_i})Q^T\hat{u}\right]$$



# With confounding term

Adding a term for confounding is straightforward to implement

$$\hat{u} \sim N(0,R S^{-1} \Sigma_u S^{-1} R+ cI)$$
Special case:
$$ \Sigma_u= S(\sigma^2_uI)S$$

$$\hat{u} \sim N(0,\sigma^2u R^2+R+cI) $$
MAF case: 
$$\Sigma_u = S \sigma^2_u \text{diag}([2f_i(1-f_i)]^\alpha)S$$

### Likelihood

$$L(\hat{u})=\frac{-1}{2} |R S^{-1} \Sigma_u S^{-1} R + R + cI | -\frac{1}{2} \hat{u}^T(R S^{-1} \Sigma_u S^{-1} R + R + cI)^{-1}\hat{u}$$


# Results

[Read more about the large and small simulations](simulation.html)

In the first plot, I show the estimate of PVE ($\hat{PVE}$) vs the true PVE. Remember that $\hat{PVE}=\frac{p}{n}\hat{\sigma^2_u}$.  This is without confounding.  In the second plot, I show the $\text{RMSE}(PVE)$ of the model that takes confounding into account (`Confound`) vs the model that doesn't take confounding into account (`No_Confound`), with increasing levels of counfounding `c = 0,0.1,0.2`


## Smaller Dataset


```{r libs,echo=F,message=F,warning=F}
library(RcppEigenH5)
library(RSSp)
library(tidyverse)
```

```{r filenames,echo=F,message=F,warning=F}
small_genof <- "/home/nwknoblauch/Dropbox/eqtl_estimation/data/RSS_examples/genotype2.mat"
small_evdf <- "../data/polygenic_sim_genotype2/small_evd.h5"
small_dirf <- "../data/polygenic_sim_genotype2/"
small_simf <- "../data/polygenic_sim_genotype2/simulation2.RDS"

large_genof <- "/home/nwknoblauch/Downloads/genotype.h5"
large_evdf <- "../data/polygenic_sim_genotype/large_sim_evd.h5"
large_dirf <- "../data/polygenic_sim_genotype/"
result_dir <- "../output/polygenic_sim_genotype/"


pve <- as.numeric(seq(0.01,0.3,length.out = 3))
bias <- as.numeric(seq(0.0,0.5,length.out = 5))
nreps <- 10
SNP <- scale(t(RcppEigenH5::read_2d_mat_h5(small_genof,"/","C")),center=T,scale=F)
#asimf <- gen_sim(SNP,pve,bias,nreps =nreps,outdir = small_dirf)
asimf <- "../data/polygenic_sim_genotype2/simulation14.RDS"
p <- ncol(SNP)
est_df <- estimate_RSSp_files(small_evdf,asimf,small_genof,chunksize = p,R_dataname = "shrink_R",doNoConfound = T,doLog=F,result_dir=result_dir) %>% mutate(doLog=F)
saveRDS(est_df,"../output/small_polygenic_sim.RDS")
# est_df_l <- estimate_RSSp_files(small_evdf,asimf,small_genof,chunksize = p,R_dataname = "shrink_R",doNoConfound = T,doLog=T) %>% mutate(doLog=T)
# est_df <- bind_rows(est_df_nl,est_df_l)
```




```{r plot_pve_nc_small}
est_df <- readRDS("../output/small_polygenic_sim.RDS")
filter(est_df,method=="NoConfound",tbias==0) %>% ggplot(aes(x=tpve,y=pve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("PVE Estimates in the Absence of Confounding")+geom_abline(intercept=0,slope=1)
```





```{r plot_pve_inflation_small}
filter(est_df) %>% ggplot(aes(x=tpve,y=pve,col=tbias/tpve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Not accounting for confounding inflates PVE estimates")+geom_abline(intercept=0,slope=1)+facet_wrap(~method,labeller=label_both)
```


```{r plot_pve_rmse_small}
library(ggjoy)
filter(est_df) %>% ggplot(aes(x=tbias/tpve,y=abs(pve-tpve)/tpve,col=method))+geom_point()+geom_smooth()+ggtitle("Accounting for confounding improves PVE estimates","when confounding is high relative to PVE")+xlab("Confounding (Prop of PVE)")+ylab("RMSE(PVE)/PVE")
```

```{r plot_rmse_joy_small}
library(ggjoy)
ggplot(est_df,aes(x=abs(pve-tpve)/tpve,y=factor(tbias/tpve),col=method,fill=method))+geom_joy(panel_scaling=F)+ggtitle("Accounting for confounding improves PVE estimates","when confounding is high relative to PVE")+xlab("RMSE(PVE)/PVE")+ylab("Confound/PVE")+scale_x_log10()
```



```{r plot_confound_small}
filter(est_df,method=="Confound") %>% ggplot(aes(x=tbias,y=a_hat))+geom_point()+geom_abline(intercept=0,slope=1)+geom_smooth(method="lm")+ggtitle("Confounding is Consistently Underestimated")+xlab("True Confounding")+ylab("Estimate of Confounding")
```



Here we see that when estimating parameters in log-space,the confounding estimate is actually *more* likely to get "stuck" near zero. This might be due to the unconstrained optimizer choosing very large negative values for the log of the confounding.

# Larger Dataset


```{r large_sim}
large_genof <- "/home/nwknoblauch/Downloads/genotype.h5"
large_evdf <- "../data/polygenic_sim_genotype/large_sim_evd.h5"
large_dirf <- "../data/polygenic_sim_genotype/"
large_result_dir <- "../output/polygenic_sim_large/"



pve <- as.numeric(seq(0.01,0.3,length.out = 3))
bias <- as.numeric(seq(0.0,0.5,length.out = 5))
nreps <- 10


SNP <- scale(t(RcppEigenH5::read_2d_mat_h5(large_genof,"/","C")),center=T,scale=F)
p <- ncol(SNP)
#large_simf <- gen_sim(SNP,pve,bias,nreps =nreps,outdir = large_dirf)
large_simf <- "../data/polygenic_sim_genotype/simulation12.RDS"
tsimf <- readRDS(large_simf)
 # large_simf <- "../data/polygenic_sim_genotype/simulation5.RDS"

tsimf <- readRDS(large_simf)
p <- tsimf$p
n <- tsimf$n
est_df_large <- estimate_RSSp_files(large_evdf,large_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=F) %>% mutate(doLog=F)
saveRDS(est_df_large,"../output/polygenic_sim_large.RDS")
# est_df_l <- estimate_RSSp_files(large_evdf,large_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=T) %>% mutate(doLog=T)
# est_df_large <- est_df_nl


```

```{r plot_pve_nc_large}
est_df_large <- readRDS("../output/polygenic_sim_large.RDS")
filter(est_df_large,method=="NoConfound",tbias==0) %>% ggplot(aes(x=tpve,y=pve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("PVE Estimates in the Absence of Confounding")+geom_abline(intercept=0,slope=1)
```


```{r plot_pve_inflation_large}
filter(est_df_large) %>% ggplot(aes(x=tpve,y=pve,col=tbias/tpve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Not accounting for confounding inflates PVE estimates")+geom_abline(intercept=0,slope=1)+facet_wrap(~method,labeller=label_both)
```


```{r plot_pve_rmse_large}
filter(est_df_large) %>% ggplot(aes(x=tbias/tpve,y=abs(pve-tpve)/tpve,col=method))+geom_point()+geom_smooth()+ggtitle("Accounting for confounding marginally improves PVE estimates","when confounding is high relative to PVE")+xlab("Confounding (Prop of PVE)")+ylab("RMSE(PVE)/PVE")
# library(ggjoy)

# filter(est_df_large) %>% ggplot(aes(x=tbias,y=abs(pve-tpve),col=method))+geom_point()+geom_smooth()+ggtitle("RMSE(PVE) with increasing Levels of confounding","Linear space vs Log space")+xlab("Confounding")+ylab("RMSE(PVE)")+facet_wrap(~doLog,labeller=label_both)
```

```{r plot_rmse_joy_large}
ggplot(est_df_large,aes(x=abs(pve-tpve)/tpve,y=factor(tbias/tpve),col=method,fill=method))+geom_joy(panel_scaling=F)+ggtitle("Accounting for confounding improves PVE estimates","when confounding is high relative to PVE")+xlab("RMSE(PVE)/PVE")+ylab("Confound/PVE")+scale_x_log10()+geom_vline(xintercept=1)
```



For the larger dataset, the two-parameter model doesn't seem to be appreciably better at the levels of confounding I used.


```{r plot_confound_large}
filter(est_df_large,method=="Confound") %>% ggplot(aes(x=tbias,y=a_hat))+geom_point()+geom_abline(intercept=0,slope=1)+geom_smooth(method="lm")+ggtitle("Confounding is Consistently Underestimated")+xlab("True Confounding")+ylab("Estimate of Confounding")

```


# "Direct" simulation


Instead of simulating genotype, phenotype, $\hat{\beta}$, etc. we can simply directly simulate $\hat{u}$ given $R$, $n$, $\sigma_u$, and $c$. The results are
overall similar

```{r direct_sim}
large_genof <- "/home/nwknoblauch/Downloads/genotype.mat"
large_evdf <- "../data/polygenic_sim_genotype/large_sim_evd.h5"
large_dirf <- "../data/polygenic_sim_genotype_direct/"
large_dresult_dir <- "../output/polygenic_sim_large_direct"

R <- read_2d_mat_h5(large_genof,"/","R")
p <- ncol(R)
#n <- 1458
# pve <- as.numeric(seq(0.01,0.9,length.out = 10))
# bias <- as.numeric(seq(0.0,0.1,length.out = 5))
# nreps <- 7
# 


pve <- as.numeric(seq(0.01,0.3,length.out = 3))
bias <- as.numeric(seq(0.0,0.5,length.out = 5))
nreps <- 10


# SNP <- scale(t(RcppEigenH5::read_2d_mat_h5(large_genof,"/","C")),center=T,scale=F)


 ndir_simf <- "../data/polygenic_sim_genotype_direct/simulation3.RDS"
 tsimf <- readRDS(ndir_simf)
 p <- tsimf$p
 n <- tsimf$n
# ndir_simf <- gen_sim_direct(R = R,pve = pve,bias = bias,nreps = nreps,outdir = large_dirf,n = n)


dest_df_large <- estimate_RSSp_files(large_evdf,ndir_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=F,result_dir=large_dresult_dir) %>% mutate(doLog=F)



```




```{r plot_pve_nc_direct}

filter(dest_df_large,method=="NoConfound",tbias==0) %>% ggplot(aes(x=tpve,y=pve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Estimate of PVE vs True PVE","No confounding")+geom_abline(intercept=0,slope=1)
```




```{r plot_pve_inflation_direct}
filter(dest_df_large) %>% ggplot(aes(x=tpve,y=pve,col=tbias/tpve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Not accounting for confounding inflates PVE estimates","Direct Simulation")+geom_abline(intercept=0,slope=1)+facet_wrap(~method,labeller=label_both)
```



```{r plot_pve_rmse_direct}
filter(dest_df_large) %>% ggplot(aes(x=tbias/(tbias+tpve),y=abs(pve-tpve),col=method))+geom_point()+geom_smooth()+ggtitle("RMSE(PVE)/PVE with increasing Levels of confounding","'Direct' Simulation")+xlab("Confounding (as a proportion of PVE)")+ylab("RMSE(PVE)/PVE")
```


```{r plot_rmse_joy_direct}
ggplot(dest_df_large,aes(x=abs(pve-tpve)/tpve,y=factor(tbias/tpve),col=method,fill=method))+geom_joy(panel_scaling=F)+ggtitle("Accounting for confounding improves PVE estimates","when confounding is high relative to PVE")+xlab("RMSE(PVE)/PVE")+ylab("Confound/PVE")+scale_x_log10()+geom_vline(xintercept=1)
```



```{r plot_counfound_direct}
filter(dest_df_large,method=="Confound") %>% ggplot(aes(x=tbias,y=a_hat))+geom_point()+geom_abline(intercept=0,slope=1)+geom_smooth(method="lm")+ggtitle("Estimate of Counfounding is Close to Ideal","Under direct simulation")+xlab("True Confounding")+ylab("Estimate of Confounding")
```


## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```



