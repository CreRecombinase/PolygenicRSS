---
title: "Polygenic Estimation With and Without Confounding"
author: "Nicholas Knoblauch"
date: 2017-07-28
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->


<!-- # Background -->

<!-- ##General properties of compound normal -->

<!-- If $$x|\mu \sim N(A\mu,\Sigma)$$ and $$\mu \sim N(\rho,\Lambda)$$ then the marginalized form of $x$ is $$x \sim N(A\rho,A \Lambda A^{T} + \Sigma)$$ -->

<!-- ## RSS polygenic prior on $\beta$ -->

<!-- According to the RSS likelihood: -->

<!-- $$\hat{\beta}|\beta \sim N(SRS^{-1}\beta,SRS)$$ Where $R$ is the population LD matrix, and $S$ is a diagonal matrix with entires $S_{jj}=\frac{1}{\text{se}(\hat{\beta}_j)}$  This means that if $\beta \sim N(0,I\sigma_{\beta}^2)$ , then we can obtain the the marginalized form of $\hat{\beta}$ by substituting $$A=SRS^{-1}$$ $$\rho=0$$ $$\Lambda=I\sigma_{\beta}^2$$  and $$\Sigma=SRS$$ -->


<!-- $$\hat{\beta} \sim N(0,(SRS^{-1})I\sigma_{\beta}^2(SRS^{-1})^{T}+SRS)=N(0,\sigma_{\beta}^2 SRS^{-2}RS+SRS)$$ -->

# RSS with standardized effect size and polygenic prior

If we define $\hat{u_i}=\hat{\beta_i}/s_i$ ,the likelihood becomes

$$\hat{u}|u \sim N(Ru,R)$$

The marginalized form is 

$$\hat{u} \sim N(0,\sigma^2_uR^2+R)$$
Let $V(\sigma_u) = \sigma_u^2R^2+R=\sigma^2_u(R+\frac{1}{\sigma^2_u}I)R$

Using an eigen decomposition of $R$ ($R=QDQ^T$), we arrive at the log-likelihood function:

$$l(\sigma_u)=-\frac{1}{2}\left[\sum_i \log(d_i\sigma_u^2+1) + \hat{u}^TQ\text{diag}(\frac{1}{d_i^2\sigma_u^2+d_i})Q^T\hat{u}\right]$$



# With confounding term

Adding a term for confounding is straightforward to implement

$$\hat{u} \sim N(0,R S^{-1} \Sigma_u S^{-1} R+ cI)$$
Special case:
$$ \Sigma_u= S(\sigma^2_uI)S$$

$$\hat{u} \sim N(0,\sigma^2u R^2+R+cI) $$
MAF case: 
$$\Sigma_u = S \sigma^2_u \text{diag}([2f_i(1-f_i)]^\alpha)S$$

### Likelihood

$$L(\hat{u})=\frac{-1}{2} |R S^{-1} \Sigma_u S^{-1} R + R + cI | -\frac{1}{2} \hat{u}^T(R S^{-1} \Sigma_u S^{-1} R + R + cI)^{-1}\hat{u}$$


# Results

[Read more about the large and small simulations](simulation.html)

In the first plot, I show the estimate of PVE ($\hat{PVE}$) vs the true PVE. Remember that $\hat{PVE}=\frac{p}{n}\hat{\sigma^2_u}$.  This is without confounding.  In the second plot, I show the $\text{RMSE}(PVE)$ of the model that takes confounding into account (`Confound`) vs the model that doesn't take confounding into account (`No_Confound`), with increasing levels of counfounding `c = 0,0.1,0.2`


## Smaller Dataset


```{r filenames,echo=F,message=F,warning=F}
library(RcppEigenH5)
library(RSSp)
library(tidyverse)
small_genof <- "/home/nwknoblauch/Dropbox/eqtl_estimation/data/RSS_examples/genotype2.mat"
small_evdf <- "../data/polygenic_sim_genotype2/small_evd.h5"
small_dirf <- "../data/polygenic_sim_genotype2/"
small_simf <- "../data/polygenic_sim_genotype2/simulation2.RDS"

large_genof <- "/home/nwknoblauch/Downloads/genotype.h5"
large_evdf <- "../data/polygenic_sim_genotype/large_sim_evd.h5"
large_dirf <- "../data/polygenic_sim_genotype/"


pve <- as.numeric(seq(0.01,0.9,length.out = 10))
bias <- as.numeric(seq(0.0,0.1,length.out = 5))
nreps <- 7
SNP <- scale(t(RcppEigenH5::read_2d_mat_h5(small_genof,"/","C")),center=T,scale=F)
# asimf <- gen_sim(SNP,pve,bias,nreps =nreps,outdir = small_dirf)
p <- ncol(SNP)
est_df_nl <- estimate_RSSp_files(small_evdf,small_simf,small_genof,chunksize = p,R_dataname = "shrink_R",doNoConfound = T,doLog=F) %>% mutate(doLog=F)
est_df_l <- estimate_RSSp_files(small_evdf,small_simf,small_genof,chunksize = p,R_dataname = "shrink_R",doNoConfound = T,doLog=T) %>% mutate(doLog=T)
est_df <- bind_rows(est_df_nl,est_df_l)
```




```{r plot_small}
filter(est_df,method=="NoConfound",tbias==0) %>% ggplot(aes(x=tpve,y=pve,col=doLog))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Estimate of PVE vs True PVE","No confounding")+geom_abline(intercept=0,slope=1)
```
We see here that optimizing the log of the parameter value ($\sigma_u$) gives us the same results when we don't incorporate a confounding parameter (and there is no confounding in the data)


```{r}
library(ggjoy)
filter(est_df,abs(pve-tpve)<max(abs(pve-tpve))) %>% ggplot(aes(x=tbias,y=abs(pve-tpve),col=method))+geom_point()+geom_smooth()+ggtitle("RMSE(PVE) with increasing Levels of confounding","Linear space vs Log space")+xlab("Confounding")+ylab("RMSE(PVE)")+facet_wrap(~doLog,labeller=label_both) 
```

Here we see how RMSE increases as a function of level of confounding when there is no confounding term being estimated in the model.  We also see how poorly the 2 parameter model performs when using log-transformed parameters (right panel) compared to the two parameter model on untransformed data (left panel).


```{r}
filter(est_df,method=="Confound") %>% ggplot(aes(x=tbias,y=a_hat,col=doLog))+geom_point()+geom_abline(intercept=0,slope=1)+geom_smooth(method="lm")+ggtitle("Estimate of Counfounding vs Confounding")+xlab("True Confounding")+ylab("Estimate of Confounding")+facet_wrap(~doLog,labeller=label_both)
```
Here we see that when estimating parameters in log-space,the confounding estimate is actually *more* likely to get "stuck" near zero. This might be due to the unconstrained optimizer choosing very large negative values for the log of the confounding.

# Larger Dataset


```{r large_sim}
large_genof <- "/home/nwknoblauch/Downloads/genotype.h5"
large_evdf <- "../data/polygenic_sim_genotype/large_sim_evd.h5"
large_dirf <- "../data/polygenic_sim_genotype/"



pve <- as.numeric(seq(0.01,0.9,length.out = 10))
bias <- as.numeric(seq(0.0,0.1,length.out = 5))
nreps <- 7
# SNP <- scale(t(RcppEigenH5::read_2d_mat_h5(large_genof,"/","C")),center=T,scale=F)
# large_simf<- gen_sim(SNP,pve,bias,nreps =nreps,outdir = large_dirf)
large_simf <- "../data/polygenic_sim_genotype/simulation2.RDS"

tsimf <- readRDS(large_simf)
p <- tsimf$p
n <- tsimf$n
est_df_nl <- estimate_RSSp_files(large_evdf,large_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=F) %>% mutate(doLog=F)
est_df_l <- estimate_RSSp_files(large_evdf,large_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=T) %>% mutate(doLog=T)
est_df_large <- bind_rows(est_df_nl,est_df_l)


```

```{r}
filter(est_df_large,method=="NoConfound",tbias==0) %>% ggplot(aes(x=tpve,y=pve,col=doLog))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Estimate of PVE vs True PVE","No confounding")+geom_abline(intercept=0,slope=1)
```

The performance in the larger dataset is also very good.  We also see that there is almost no difference between the (unconstrained) log-space estimates and the constrained linear-space estimates of $\hat{\text{PVE}}$

```{r}
# library(ggjoy)
filter(est_df_large) %>% ggplot(aes(x=tbias/(tbias+tpve),y=abs(pve-tpve),col=method))+geom_point()+geom_smooth()+ggtitle("RMSE(PVE) with increasing Levels of confounding")+xlab("Confounding (as a proportion of PVE)")+ylab("RMSE(PVE)")+facet_wrap(~doLog,labeller=label_both)+scale_x_log10()
# filter(est_df_large) %>% ggplot(aes(x=tbias,y=abs(pve-tpve),col=method))+geom_point()+geom_smooth()+ggtitle("RMSE(PVE) with increasing Levels of confounding","Linear space vs Log space")+xlab("Confounding")+ylab("RMSE(PVE)")+facet_wrap(~doLog,labeller=label_both)
```

For the larger dataset, the two-parameter model doesn't seem to be appreciably better at the levels of confounding I used.
```{r}
# filter(est_df_large,!doLog) %>% ggplot(aes(x=tbias,y=abs(pve-tpve),col=method))+geom_point()+geom_smooth()+ggtitle("RMSE(PVE) with increasing Levels of confounding","Not Log Transformed")+xlab("Confounding")+ylab("RMSE(PVE)")
filter(est_df_large,!doLog) %>% ggplot(aes(x=tbias/(tbias+tpve),y=abs(pve-tpve),col=method))+geom_point()+geom_smooth()+ggtitle("RMSE(PVE) with increasing Levels of confounding")+xlab("Confounding (as a proportion of PVE)")+ylab("RMSE(PVE)")+facet_wrap(~doLog,labeller=label_both)+scale_x_log10()
```




```{r}
filter(est_df_large,method=="Confound") %>% ggplot(aes(x=tbias,y=a_hat))+geom_point()+geom_abline(intercept=0,slope=1)+geom_smooth(method="lm")+ggtitle("Estimate of Counfounding vs Confounding")+xlab("True Confounding")+ylab("Estimate of Confounding")+facet_wrap(~doLog,labeller=label_both)

```



<!-- ## A closer look at some of the worst estimates -->
<!-- ```{r} -->

<!-- ncdf <- filter(est_df_large,convergence!=0) -->
<!-- table(est_df_large$convergence) -->
<!-- bad_simf <- filter(est_df_large,method=="Confound") %>% select(-chunksize,-replicate,-lnZ) %>% mutate(rmse=abs(pve-tpve),rel_rmse=abs(pve-tpve)/tpve) %>% arrange(desc(rel_rmse)) %>% slice(1:10) -->
<!-- ``` -->





## "Direct" simulation


Instead of simulating genotype, phenotype, $\hat{\beta}$, etc. we can simply directly simulate $\hat{u}$ given $R$, $n$, $\sigma_u$, and $c$. The results are
overall similar

```{r}
large_genof <- "/home/nwknoblauch/Downloads/genotype.mat"
large_evdf <- "../data/polygenic_sim_genotype/large_sim_evd.h5"
large_dirf <- "../data/polygenic_sim_genotype/"


R <- read_2d_mat_h5(large_genof,"/","R")
#n <- 1458
pve <- as.numeric(seq(0.01,0.9,length.out = 10))
bias <- as.numeric(seq(0.0,0.1,length.out = 5))
nreps <- 7
ndir_simf <- "../data/polygenic_sim_genotype/simulation4.RDS"
tsimf <- readRDS(ndir_simf)
p <- tsimf$p
n <- tsimf$n
#ndir_simf <- gen_sim_direct(R = R,pve = pve,bias = bias,nreps = nreps,outdir = large_dirf,n = n)

pve <- as.numeric(seq(0.01,0.9,length.out = 10))
bias <- as.numeric(seq(0.0,0.1,length.out = 5))
nreps <- 7
#SNP <- scale(t(RcppEigenH5::read_2d_mat_h5(large_genof,"/","C")),center=T,scale=F)
#large_simf<- gen_sim(SNP,pve,bias,nreps =nreps,outdir = large_dirf)




dest_df_nl <- estimate_RSSp_files(large_evdf,ndir_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=F) %>% mutate(doLog=F)
dest_df_l <- estimate_RSSp_files(large_evdf,ndir_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=T) %>% mutate(doLog=T)
dest_df_large <- bind_rows(dest_df_nl,dest_df_l)


# 
# est_df_nl <- estimate_RSSp_files(large_evdf,large_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=F) %>% mutate(doLog=F)
# est_df_l <- estimate_RSSp_files(large_evdf,large_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=T) %>% mutate(doLog=T)
# est_df_large <- bind_rows(est_df_nl,est_df_l)

```




```{r}
filter(dest_df_large,method=="NoConfound",tbias==0) %>% ggplot(aes(x=tpve,y=pve,col=doLog))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Estimate of PVE vs True PVE","No confounding")+geom_abline(intercept=0,slope=1)
```
The one-parameter model seems to do equally well on data directly simulated from the model.



```{r}
filter(dest_df_large,method=="NoConfound",tbias==0) %>% ggplot(aes(x=tsigu,y=sigu))+geom_point()+geom_smooth(method="lm")+xlab(expression(sigma))+ylab(expression(hat(sigma)))+ggtitle("Estimate of sigma_u vs sigma_u","No confounding")+geom_abline(intercept=0,slope=1)
```


```{r}
filter(dest_df_large) %>% ggplot(aes(x=tbias/(tbias+tpve),y=abs(pve-tpve),col=method))+geom_point()+geom_smooth()+ggtitle("RMSE(PVE) with increasing Levels of confounding")+xlab("Confounding (as a proportion of PVE)")+ylab("RMSE(PVE)")+facet_wrap(~doLog,labeller=label_both)+scale_x_log10()
```
The two parameter model doesn't seem to do any better than the one-parameter model using the levels of confounding I estimated

```{r}
filter(dest_df_large,method=="Confound") %>% ggplot(aes(x=tbias,y=a_hat))+geom_point()+geom_abline(intercept=0,slope=1)+geom_smooth(method="lm")+ggtitle("Estimate of Counfounding vs Confounding")+xlab("True Confounding")+ylab("Estimate of Confounding")+facet_wrap(~doLog,labeller=label_both)
```


## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```



