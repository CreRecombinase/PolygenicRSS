---
title: "Polygenic Estimation With and Without Confounding"
author: "Nicholas Knoblauch"
date: 2017-07-28
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->


<!-- # Background -->

<!-- ##General properties of compound normal -->

<!-- If $$x|\mu \sim N(A\mu,\Sigma)$$ and $$\mu \sim N(\rho,\Lambda)$$ then the marginalized form of $x$ is $$x \sim N(A\rho,A \Lambda A^{T} + \Sigma)$$ -->

<!-- ## RSS polygenic prior on $\beta$ -->

<!-- According to the RSS likelihood: -->

<!-- $$\hat{\beta}|\beta \sim N(SRS^{-1}\beta,SRS)$$ Where $R$ is the population LD matrix, and $S$ is a diagonal matrix with entires $S_{jj}=\frac{1}{\text{se}(\hat{\beta}_j)}$  This means that if $\beta \sim N(0,I\sigma_{\beta}^2)$ , then we can obtain the the marginalized form of $\hat{\beta}$ by substituting $$A=SRS^{-1}$$ $$\rho=0$$ $$\Lambda=I\sigma_{\beta}^2$$  and $$\Sigma=SRS$$ -->


<!-- $$\hat{\beta} \sim N(0,(SRS^{-1})I\sigma_{\beta}^2(SRS^{-1})^{T}+SRS)=N(0,\sigma_{\beta}^2 SRS^{-2}RS+SRS)$$ -->

# RSS with standardized effect size and polygenic prior

If we define $\hat{u_i}=\hat{\beta_i}/s_i$ ,the likelihood becomes

$$\hat{u}|u \sim N(Ru,R)$$

The marginalized form is 

$$\hat{u} \sim N(0,\sigma^2_uR^2+R)$$
Let $V(\sigma_u) = \sigma_u^2R^2+R=\sigma^2_u(R+\frac{1}{\sigma^2_u}I)R$

Using an eigen decomposition of $R$ ($R=QDQ^T$), we arrive at the log-likelihood function:

$$l(\sigma_u)=-\frac{1}{2}\left[\sum_i \log(d_i\sigma_u^2+1) + \hat{u}^TQ\text{diag}(\frac{1}{d_i^2\sigma_u^2+d_i})Q^T\hat{u}\right]$$



# With confounding term

Adding a term for confounding is straightforward to implement

$$\hat{u} \sim N(0,R S^{-1} \Sigma_u S^{-1} R+ cI)$$
Special case:
$$ \Sigma_u= S(\sigma^2_uI)S$$

$$\hat{u} \sim N(0,\sigma^2u R^2+R+cI) $$
MAF case: 
$$\Sigma_u = S \sigma^2_u \text{diag}([2f_i(1-f_i)]^\alpha)S$$

### Likelihood

$$L(\hat{u})=\frac{-1}{2} |R S^{-1} \Sigma_u S^{-1} R + R + cI | -\frac{1}{2} \hat{u}^T(R S^{-1} \Sigma_u S^{-1} R + R + cI)^{-1}\hat{u}$$


```{r libs,echo=F,message=F,warning=F}
library(RcppEigenH5)
library(RSSp)
library(tidyverse)
```

```{r small_sim,echo=F,message=F,warning=F}
small_genof <- "/home/nwknoblauch/Dropbox/eqtl_estimation/data/RSS_examples/genotype2.mat"
small_evdf <- "../data/polygenic_sim_genotype2/small_evd.h5"
small_dirf <- "../data/polygenic_sim_genotype2/"
small_simf <- "../data/polygenic_sim_genotype2/simulation2.RDS"

large_genof <- "/home/nwknoblauch/Downloads/genotype.h5"
large_evdf <- "../data/polygenic_sim_genotype/large_sim_evd.h5"
large_dirf <- "../data/polygenic_sim_genotype/"
result_dir <- "../output/polygenic_sim_genotype/"


pve <- as.numeric(seq(0.01,0.3,length.out = 3))
bias <- as.numeric(seq(0.0,0.5,length.out = 5))
nreps <- 10
SNP <- scale(t(RcppEigenH5::read_2d_mat_h5(small_genof,"/","C")),center=T,scale=F)
# asimf <- gen_sim(SNP,pve,bias,nreps =nreps,outdir = small_dirf)
asimf <- "../data/polygenic_sim_genotype2/simulation14.RDS"
p <- ncol(SNP)
est_df <- estimate_RSSp_files(small_evdf,asimf,small_genof,chunksize = p,R_dataname = "shrink_R",doNoConfound = T,doLog=F,result_dir=result_dir) %>% mutate(doLog=F)
saveRDS(est_df,"../output/small_polygenic_sim.RDS")
# est_df_l <- estimate_RSSp_files(small_evdf,asimf,small_genof,chunksize = p,R_dataname = "shrink_R",doNoConfound = T,doLog=T) %>% mutate(doLog=T)
# est_df <- bind_rows(est_df_nl,est_df_l)
```
# Results

There are three sets of simulations.  In the first, based on Xiang's `example2` there are `r p` SNPs and `r nrow(SNP)` individuals. 
The SNPS all come from one gene, so the average pairwise linkage is high.  

The second example is based on Xiang's `example`, where we have `r get_rownum_h5(large_genof,"/","C")` SNPs (and the same number of individuals).  These SNPs come from chromosome 16.

The final example is also based on Xiang's `example`, but instead of simulating GWAS data, data is sampled directly from the multivariate normal distribution specified by $\sigma_u$, $c$, and $R$.


[Read more about the details of simulation here](simulation.html)



In the first plot, I show the estimate of PVE ($\hat{PVE}$) vs the true PVE. Remember that $\hat{PVE}=\frac{p}{n}\hat{\sigma^2_u}$.  This is without confounding.  In the second plot, I show the $\text{RMSE}(PVE)$ of the model that takes confounding into account (`Confound`) vs the model that doesn't take confounding into account (`No_Confound`), with increasing levels of counfounding `r bias`.  

## Smaller Dataset

```{r plot_pve_nc_small}
est_df <- readRDS("../output/small_polygenic_sim.RDS")
filter(est_df,method=="NoConfound",tbias==0) %>% ggplot(aes(x=tpve,y=pve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("PVE Estimates in the Absence of Confounding")+geom_abline(intercept=0,slope=1)
```

This plot shows what estimates of PVE look like when there is no confounding in the data and no confounding in the model.  The black line is a slope 1 line through the origin, and the blue line is an OLS fit (the grey area represents standard error).



```{r plot_pve_inflation_small}
filter(est_df) %>% ggplot(aes(x=tpve,y=pve,col=tbias/tpve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Not accounting for confounding inflates PVE estimates")+geom_abline(intercept=0,slope=1)+facet_wrap(~method,labeller=label_both)+guides(col=guide_legend(title=bquote(frac(c,PVE))))
```

This plot shows how confounding can inflate PVE estimates when there is no term for confounding in the model. On the left is the two-parameter model that has a term for confounding, and on the right is the one-parameter model that does not.  The color in this plot represents the ratio of amount of confounding to true PVE. 
```{r plot_pve_rmse_small}
library(ggjoy)
filter(est_df) %>% rename(PVE=tpve) %>% ggplot(aes(x=tbias/PVE,y=abs(pve-PVE)/PVE,col=method))+geom_point()+geom_smooth()+ggtitle("Accounting for confounding improves PVE estimates","when confounding is high relative to PVE, and when PVE is high")+xlab(bquote(frac(c,PVE)))+ylab(bquote(frac(RMSE[PVE],PVE)))+facet_wrap(~PVE,labeller=label_both)
```

This plot shows how when the true PVE is relatively low, the two-parameter model and one-parameter model perform about equally.  As the true PVE increases, the performance of the two models diverges as a function of the level of confounding.  At high (and moderate) PVE, the two parameter model's performance is relatively consistent, while the one-parameter model's performance degrades as the amount of confounding increases.  


```{r plot_rmse_joy_small}
library(ggjoy)
rename(est_df,PVE=tpve) %>% ggplot(aes(x=abs(pve-PVE)/PVE,y=factor(tbias/PVE),col=method,fill=method))+geom_joy(panel_scaling=T)+ggtitle("Accounting for confounding improves PVE estimates","when confounding is high relative to PVE")+ylab(bquote(frac(c,PVE)))+xlab(bquote(frac(RMSE[PVE],PVE)))+scale_x_log10()+facet_wrap(~PVE,labeller=label_both)
```

This is another visualization of the same data. Note the log10 scale along the x-axis.

```{r bias_by_pve_small}

filter(est_df,method=="Confound") %>% rename(pve_est=pve) %>% rename(pve=tpve) %>%  ggplot(aes(x=tbias/pve,y=a_hat/pve))+geom_point()+geom_abline(intercept=0,slope=1)+geom_smooth(method="lm")+ggtitle("Confounding is Consistently Underestimated","When True PVE is low")+xlab(bquote(frac(c,PVE)))+ylab(bquote(frac(hat(c),PVE)))+facet_wrap(~pve,labeller = label_both)

```


Switching now only to the two-parameter model, we see that at low PVE, the level of confounding (as a proportion of total PVE) is badly underestimated.  At moderate to high PVE, the performance improves, but there does seem to be a consistent underestimation of the level of confounding.

# Larger Dataset


```{r large_sim}
large_genof <- "/home/nwknoblauch/Downloads/genotype.h5"
large_evdf <- "../data/polygenic_sim_genotype/large_sim_evd.h5"
large_dirf <- "../data/polygenic_sim_genotype/"
large_result_dir <- "../output/polygenic_sim_large/"



pve <- as.numeric(seq(0.01,0.3,length.out = 3))
bias <- as.numeric(seq(0.0,0.5,length.out = 5))
nreps <- 10


SNP <- scale(t(RcppEigenH5::read_2d_mat_h5(large_genof,"/","C")),center=T,scale=F)
p <- ncol(SNP)
#large_simf <- gen_sim(SNP,pve,bias,nreps =nreps,outdir = large_dirf)
large_simf <- "../data/polygenic_sim_genotype/simulation12.RDS"
tsimf <- readRDS(large_simf)
 # large_simf <- "../data/polygenic_sim_genotype/simulation5.RDS"

tsimf <- readRDS(large_simf)
p <- tsimf$p
n <- tsimf$n
est_df_large <- estimate_RSSp_files(large_evdf,large_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=F) %>% mutate(doLog=F)
saveRDS(est_df_large,"../output/polygenic_sim_large.RDS")
# est_df_l <- estimate_RSSp_files(large_evdf,large_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=T) %>% mutate(doLog=T)
# est_df_large <- est_df_nl


```

```{r plot_pve_nc_large}
est_df_large <- readRDS("../output/polygenic_sim_large.RDS")
filter(est_df_large,method=="NoConfound",tbias==0) %>% ggplot(aes(x=tpve,y=pve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("PVE Estimates in the Absence of Confounding")+geom_abline(intercept=0,slope=1)
```

This plot shows what estimates of PVE look like when there is no confounding in the data and no confounding in the model.  The black line is a slope 1 line through the origin, and the blue line is an OLS fit (the grey area represents standard error). 


```{r plot_pve_inflation_large}
filter(est_df_large) %>% ggplot(aes(x=tpve,y=pve,col=tbias/tpve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Not accounting for confounding inflates PVE estimates")+geom_abline(intercept=0,slope=1)+facet_wrap(~method,labeller=label_both)+guides(col=guide_legend(title=bquote(frac(c,PVE))))
```


```{r plot_pve_rmse_large}
filter(est_df_large) %>% rename(PVE=tpve) %>% ggplot(aes(x=tbias/PVE,y=abs(pve-PVE)/PVE,col=method))+geom_point()+geom_smooth()+ggtitle("Accounting for confounding improves PVE estimates","when confounding is high relative to PVE, and when PVE is high")+xlab(bquote(frac(c,PVE)))+ylab(bquote(frac(RMSE[PVE],PVE)))+facet_wrap(~PVE,labeller=label_both)



# filter(est_df_large) %>% ggplot(aes(x=tbias,y=abs(pve-tpve),col=method))+geom_point()+geom_smooth()+ggtitle("RMSE(PVE) with increasing Levels of confounding","Linear space vs Log space")+xlab("Confounding")+ylab("RMSE(PVE)")+facet_wrap(~doLog,labeller=label_both)
```

```{r plot_rmse_joy_large}
library(ggjoy)
rename(est_df_large,PVE=tpve) %>% ggplot(aes(x=abs(pve-PVE)/PVE,y=factor(tbias/PVE),col=method,fill=method))+geom_joy(panel_scaling=T)+ggtitle("Accounting for confounding improves PVE estimates","when confounding is high relative to PVE")+ylab(bquote(frac(c,PVE)))+xlab(bquote(frac(RMSE[PVE],PVE)))+scale_x_log10()+facet_wrap(~PVE,labeller=label_both)
```



```{r plot_confound_large}
filter(est_df_large,method=="Confound") %>% rename(pve_est=pve) %>% rename(pve=tpve) %>%  ggplot(aes(x=tbias/pve,y=a_hat/pve))+geom_point()+geom_abline(intercept=0,slope=1)+geom_smooth(method="lm")+ggtitle("Confounding is Consistently Underestimated","When True PVE is low")+xlab(bquote(frac(c,PVE)))+ylab(bquote(frac(hat(c),PVE)))+facet_wrap(~pve,labeller = label_both)




```

# "Direct" simulation


Instead of simulating genotype, phenotype, $\hat{\beta}$, etc. we can simply directly simulate $\hat{u}$ given $R$, $n$, $\sigma_u$, and $c$. The results are
overall similar

```{r direct_sim}
large_genof <- "/home/nwknoblauch/Downloads/genotype.mat"
large_evdf <- "../data/polygenic_sim_genotype/large_sim_evd.h5"
large_dirf <- "../data/polygenic_sim_genotype_direct/"
large_dresult_dir <- "../output/polygenic_sim_large_direct"

R <- read_2d_mat_h5(large_genof,"/","R")
p <- ncol(R)
#n <- 1458
# pve <- as.numeric(seq(0.01,0.9,length.out = 10))
# bias <- as.numeric(seq(0.0,0.1,length.out = 5))
# nreps <- 7
# 


pve <- as.numeric(seq(0.01,0.3,length.out = 3))
bias <- as.numeric(seq(0.0,0.5,length.out = 5))
nreps <- 10


# SNP <- scale(t(RcppEigenH5::read_2d_mat_h5(large_genof,"/","C")),center=T,scale=F)


 ndir_simf <- "../data/polygenic_sim_genotype_direct/simulation3.RDS"
 tsimf <- readRDS(ndir_simf)
 p <- tsimf$p
 n <- tsimf$n
# ndir_simf <- gen_sim_direct(R = R,pve = pve,bias = bias,nreps = nreps,outdir = large_dirf,n = n)


dest_df_large <- estimate_RSSp_files(large_evdf,ndir_simf,large_genof,chunksize = p,R_dataname = "R",doNoConfound = T,doLog=F,result_dir=large_dresult_dir) %>% mutate(doLog=F)



```




```{r plot_pve_nc_direct}

filter(dest_df_large,method=="NoConfound",tbias==0) %>% ggplot(aes(x=tpve,y=pve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Estimate of PVE vs True PVE","No confounding")+geom_abline(intercept=0,slope=1)
```




```{r plot_pve_inflation_direct}
filter(dest_df_large) %>% ggplot(aes(x=tpve,y=pve,col=tbias/tpve))+geom_point()+geom_smooth(method="lm")+xlab(expression(paste("PVE")))+ylab(expression(hat("PVE")))+ggtitle("Not accounting for confounding inflates PVE estimates")+geom_abline(intercept=0,slope=1)+facet_wrap(~method,labeller=label_both)+guides(col=guide_legend(title=bquote(frac(c,PVE))))
```



```{r plot_pve_rmse_direct}
library(ggjoy)
filter(dest_df_large) %>% rename(PVE=tpve) %>% ggplot(aes(x=tbias/PVE,y=abs(pve-PVE)/PVE,col=method))+geom_point()+geom_smooth()+ggtitle("Accounting for confounding improves PVE estimates","when confounding is high relative to PVE, and when PVE is high")+xlab(bquote(frac(c,PVE)))+ylab(bquote(frac(RMSE[PVE],PVE)))+facet_wrap(~PVE,labeller=label_both)
```


```{r plot_rmse_joy_direct}
library(ggjoy)
rename(dest_df_large,PVE=tpve) %>% ggplot(aes(x=abs(pve-PVE)/PVE,y=factor(tbias/PVE),col=method,fill=method))+geom_joy(panel_scaling=T)+ggtitle("Accounting for confounding improves PVE estimates","when confounding is high relative to PVE")+ylab(bquote(frac(c,PVE)))+xlab(bquote(frac(RMSE[PVE],PVE)))+scale_x_log10()+facet_wrap(~PVE,labeller=label_both)

```



```{r plot_counfound_direct}
filter(dest_df_large,method=="Confound") %>% rename(pve_est=pve) %>% rename(pve=tpve) %>%  ggplot(aes(x=tbias/pve,y=a_hat/pve))+geom_point()+geom_abline(intercept=0,slope=1)+geom_smooth(method="lm")+ggtitle("Confounding is Consistently Underestimated","When True PVE is low")+xlab(bquote(frac(c,PVE)))+ylab(bquote(frac(hat(c),PVE)))+facet_wrap(~pve,labeller = label_both)

```

For the direct simulation, although the low PVE scenario seems to be noiser, the estimates are always centered around the true value.





## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```



